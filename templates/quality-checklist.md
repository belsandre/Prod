# Quality Checklist Template

**Purpose**: Universal quality standards for research workflows to ensure completeness, accuracy, and proper documentation before deliverable submission.

---

## How to Use This Checklist

1. **During Work**: Keep quality standards in mind, don't wait until end
2. **Mid-Project**: Run spot checks every 3-5 deliverables
3. **Pre-Submission**: Complete full checklist before marking workflow complete
4. **Fix Issues**: Address all failures before proceeding to submission

---

## Universal Quality Standards

### Completeness ✅

**All Required Deliverables Exist**:
- [ ] All primary research items completed (entities, documents, analyses)
- [ ] All required output files/folders present
- [ ] No placeholders or "TODO" sections remaining
- [ ] Cross-references between documents valid

**Scope Coverage**:
- [ ] All items from scope/priority list addressed
- [ ] If items skipped, documented with justification
- [ ] No orphaned work (partial research without completion)

---

### Content Quality ✅

**Substantive Depth**:
- [ ] Research documents are comprehensive (not superficial bullet points)
- [ ] Analysis documents cite specific evidence
- [ ] Conclusions supported by data/sources
- [ ] Critical assessment included (risks, limitations, trade-offs)

**Accuracy**:
- [ ] Facts distinguished from projections/speculation
- [ ] No inferred information without labeling as such
- [ ] Inconsistencies reconciled or documented
- [ ] Dates, numbers, names verified for accuracy

**Clarity**:
- [ ] Documents well-structured with clear sections
- [ ] Technical terms defined or explained
- [ ] Findings actionable and clear
- [ ] Executive summaries concise (2-3 pages typical)

---

### Source Documentation ✅

**Source Attribution**:
- [ ] Every claim has source attribution (inline or footnote)
- [ ] High-value sources saved as separate files
- [ ] Source files properly formatted (see templates/source-documentation.md)
- [ ] Source distribution appropriate (mix of external, company, dataroom per tier guidelines)

**Source Metadata Complete**:
- [ ] All source files include URL field (full URL, not just domain)
- [ ] All source files include Date field in YYYY-MM-DD format
- [ ] All source files include Source Type
- [ ] All source files include Objectivity Level assessment
- [ ] Source URLs working (spot check 10% sample)

**Source Content**:
- [ ] Key information extracted and documented
- [ ] Critical assessment included (strengths, limitations, biases)
- [ ] Raw content preserved for verification
- [ ] Evidence tier classification applied (if applicable)

---

### File Structure ✅

**Required Directories Present**:
- [ ] Input/source material directories
- [ ] Output/deliverable directories
- [ ] Process tracking directories (if applicable)
- [ ] Analysis/synthesis directories

**Naming Conventions**:
- [ ] Files named consistently (kebab-case or consistent format)
- [ ] No spaces in file names (use hyphens or underscores)
- [ ] File names descriptive and findable
- [ ] Dated versions clearly marked (YYYY-MM-DD format)

**File Organization**:
- [ ] Related files grouped in appropriate folders
- [ ] No files in wrong locations
- [ ] No duplicate files (unless explicitly versioned)
- [ ] README or index file present (if applicable)

---

### Attribution & Verification ✅

**Claim Verification**:
- [ ] High-value claims verified when possible
- [ ] Verification attempts documented (even if unsuccessful)
- [ ] Unverified claims clearly labeled
- [ ] Contradictory information reconciled or flagged

**Dataroom Claims**:
- [ ] Dataroom sources clearly labeled with ⚠️⚠️ markers
- [ ] External validation attempted for high-value claims
- [ ] Verification failures documented as research limitations
- [ ] No unattributed dataroom claims presented as fact

**Evidence Quality**:
- [ ] Evidence tiers applied appropriately (Tier 1/2/3 if using system)
- [ ] Citation formats correct per evidence tier
- [ ] Independent sources prioritized over interested-party sources
- [ ] Source quality distribution appropriate for research tier

---

### Cross-Document Consistency ✅

**Internal Consistency**:
- [ ] Facts consistent across all documents
- [ ] Cross-references valid (no broken links)
- [ ] Terminology consistent throughout
- [ ] Dates, names, numbers match across documents

**Progress Tracking Alignment**:
- [ ] Progress tracker reflects actual completion status
- [ ] File system matches progress tracker claims
- [ ] Completion dates filled in
- [ ] Final status updated to "Complete"

**Summary Documents Accurate**:
- [ ] Executive summary reflects actual findings
- [ ] Analysis documents consistent with underlying research
- [ ] No information in summaries without source research
- [ ] Priority/tier classifications consistent

---

## Workflow-Specific Checklists

### Research Workflows (Companies, People, Topics)

**Entity-Specific**:
- [ ] All priority entities researched
- [ ] Source quality thresholds met per tier
- [ ] Entity profiles complete (all required sections)
- [ ] Relationships documented (if applicable)

**Research Depth**:
- [ ] Tier 1: Deep research (5+ sources, comprehensive analysis)
- [ ] Tier 2: Standard research (3+ sources, solid coverage)
- [ ] Tier 3: Basic research (2+ sources, key facts)

### Analysis Workflows (Assessments, Evaluations)

**Analytical Components**:
- [ ] Scoring/evaluation framework applied consistently
- [ ] All dimensions assessed (no gaps)
- [ ] Comparative analysis where appropriate
- [ ] Strengths AND weaknesses documented

**Evidence-Based**:
- [ ] Conclusions tied to specific evidence
- [ ] Qualitative and quantitative support
- [ ] Edge cases or exceptions noted
- [ ] Confidence levels stated (if applicable)

### Synthesis Workflows (Executive Summaries, Reports)

**Synthesis Quality**:
- [ ] Key insights clearly articulated
- [ ] Supporting evidence referenced
- [ ] Actionable recommendations provided
- [ ] Appropriate caveats and limitations noted

**Audience-Appropriate**:
- [ ] Technical depth matches audience
- [ ] Executive summary concise (2-3 pages)
- [ ] No unexplained jargon
- [ ] Clear next steps or implications

---

## Quality Spot Checks (During Work)

**Every 3-5 Deliverables, Pause to Check**:
1. Are deliverables substantive or just superficial?
2. Are sources properly formatted and saved?
3. Did we meet quality thresholds?
4. Any issues to document in progress tracker?

**Mid-Project Quality Gate**:
- Review first 3 completed items in detail
- Identify patterns of issues
- Adjust approach for remaining items
- Document quality adjustments made

---

## Pre-Submission Checklist Summary

**Before marking workflow complete, verify ALL sections above, then confirm**:

- [ ] **Completeness**: All deliverables exist, no TODOs
- [ ] **Content Quality**: Substantive, accurate, clear
- [ ] **Source Documentation**: Complete metadata, attribution, quality
- [ ] **File Structure**: Organized, named consistently, no duplicates
- [ ] **Attribution & Verification**: Claims verified, dataroom labeled, evidence quality appropriate
- [ ] **Cross-Document Consistency**: Facts consistent, references valid, progress tracking aligned

**If ANY item unchecked**: Address before submission. Document if unable to address with justification.

---

## Failure Remediation

### Critical Failures (Must Fix)
- Missing required deliverables
- Unattributed claims or missing sources
- Broken cross-references
- Factual inconsistencies
- Misleading dataroom claims

**Action**: Stop, fix immediately, re-verify

### Warnings (Should Address)
- Source metadata incomplete
- Quality thresholds not quite met
- Minor organizational issues
- Verification attempts partial

**Action**: Fix if time permits, document if deferring

### Optional Improvements
- Additional depth possible
- More sources could be added
- Structure could be refined

**Action**: Note for future iterations, not blocking

---

## Quality Validation Methods

### Self-Check
- Review each checklist item methodically
- Spot-check sample of work (10-20%)
- Trace claims back to sources

### Automated Checks (If Available)
- Run validator.md workflow (if applicable)
- Check file structure programmatically
- Validate URLs and metadata fields

### Peer Review (If Available)
- Have colleague review for clarity
- Test if conclusions supported by evidence
- Check for missing context or assumptions

---

## Documentation of Limitations

**When quality standards cannot be fully met, document explicitly**:

```markdown
## Research Limitations

This research has the following limitations that users should be aware of:

1. **Source Availability**: [Describe constraints]
   - Impact: [How this affects findings]
   - Mitigation: [What was done to address]

2. **Verification Gaps**: [Describe unverified claims]
   - Impact: [How this affects confidence]
   - Recommendation: [How to address in future]

3. **Scope Constraints**: [Describe what wasn't covered]
   - Impact: [How this affects completeness]
   - Note: [Why constraint exists]
```

---

## Usage in Workflows

**Reference this checklist by including**:
```markdown
## Quality Checklist
Before submitting deliverables, complete `templates/quality-checklist.md`:
- Completeness
- Content Quality
- Source Documentation
- File Structure
- Attribution & Verification
- Cross-Document Consistency
```

**Workflow-specific extensions**: Add domain-specific quality criteria while maintaining universal standards.
