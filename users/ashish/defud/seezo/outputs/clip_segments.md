# Short Clip Segments - Seezo Episode (Sandesh Mysore Anand)

## Clip 1: The 10% Coverage Reality Check

**Timestamps:** [00:03:21 - 00:03:42]
**Duration:** 21 seconds
**Platform:** LinkedIn

**Clip Title:** "Are You Really Doing Security?"

**Key Quote:**
> "When you have 10% coverage of a security activity, are you really doing it, is the question."

**Full Transcript Segment:**
"And, you know, most of the answers revolved around process, you know, training people, and so on and so forth, but there was no technology solution to that... And this was a real problem for me, right? Because, you know, when you have 10% coverage of a security activity, I mean, are you really doing it, is the question, right?"

**Why It Works:**
Brutally simple question that challenges fundamental assumptions. Forces viewers to confront uncomfortable truth about their security programs. Creates immediate self-reflection. Perfect conversation starter for security leaders.

**Suggested Caption:**
10% security coverage = failure. CISO founder Sandesh explains why most companies aren't actually doing threat modeling. ðŸŽ¯

**Hashtags:** #cybersecurity #threatmodeling #appsec #securityleadership #CISO

---

## Clip 2: Non-Developers Writing Code

**Timestamps:** [00:35:50 - 00:36:16]
**Duration:** 26 seconds
**Platform:** Twitter/LinkedIn

**Clip Title:** "The People Writing Your Code Were Never Trained"

**Key Quote:**
> "Product managers, designers, and sales engineers are writing code now, and we've never spent any time educating these people."

**Full Transcript Segment:**
"And now, product managers and designers and sales engineers are writing code, and we've never spent any time educating these people. Right? So we've never actually spent time training any of those folks, and they're writing more code, right? So there's more code being written, there's no budget for new AppSec engineers, and we somehow have to scale AppSec now."

**Why It Works:**
Surprising revelation that most people haven't considered. Creates "oh shit" moment. Explains why security is getting harder despite better tools. Highly shareable, timely, and relevant to current AI code gen trends.

**Suggested Caption:**
We spent 15 years teaching developers security. Now PMs and designers are generating code with AI. What could go wrong? ðŸ˜¬

**Hashtags:** #AI #security #coding #softwareengineering #appsec

---

## Clip 3: The Stark Microservice Problem

**Timestamps:** [00:13:10 - 00:13:54]
**Duration:** 44 seconds
**Platform:** LinkedIn

**Clip Title:** "Why Generic AI Security Tools Fail"

**Key Quote:**
> "One of our customers has a microservice called Stark. The LLM does not know what Stark is. Unless we can do that at scale for every company, it becomes really hard to give relevant results."

**Full Transcript Segment:**
"The second problem we faced was how do we customize this for every company? I'll give you an example. One of our customers has a microservice called Stark, okay? And Stark is their notification service. Now, the LLM does not know what Stark is, right? So every time we see Stark in an architecture document, it has no idea what the hell's going on, right? Now, but we've got to somehow tell that stock is notification service. So unless we can do that at scale for every company, it becomes really hard to kind of give relevant results and avoid LLM slop, AI slop, right?"

**Why It Works:**
Concrete example that illustrates abstract problem of AI context. Instantly relatable to anyone using AI tools. Shows the gap between AI hype and reality. Technical audience will immediately understand and share.

**Suggested Caption:**
Every company has a "Stark." Generic AI tools don't understand your context. Here's why that's a problem. ðŸ’¡

**Hashtags:** #LLMs #artificialintelligence #contextualization #appsecurity #AIchallenges

---

## Clip 4: Makers and Checkers

**Timestamps:** [00:36:41 - 00:37:07]
**Duration:** 26 seconds
**Platform:** LinkedIn/Twitter

**Clip Title:** "Why Cursor Can't Secure Itself"

**Key Quote:**
> "The history of security is a risk management function, and risk management always needs makers and checkers. The entity that's making something cannot be the entity that's also checking itself."

**Full Transcript Segment:**
"But the history of security is a risk management function, and risk management always needs makers and checkers, right? So if the entity that's making something cannot be the entity that's also checking itself, right? That just leads to the same biases creeping in. So, I think the role of AppSec should be saying, hey. If making code or building code is going this way, then how should the checker system evolve?"

**Why It Works:**
Fundamental principle explained simply. Applies beyond security to governance, compliance, quality. Timeless insight with immediate AI relevance. Philosophical yet practical. Creates debate and discussion.

**Suggested Caption:**
Can Cursor write secure code and verify it? Sandesh explains why the maker-checker principle still matters in the AI era. âš–ï¸

**Hashtags:** #security #AI #riskmanagement #governance #softwareengineering

---

## Clip 5: Security Standards Are Finally Operational

**Timestamps:** [00:20:25 - 00:21:12]
**Duration:** 47 seconds
**Platform:** LinkedIn

**Clip Title:** "Humans Don't Need to Read Security Standards Anymore"

**Key Quote:**
> "Humans don't need to read security standards anymore. LLMs can read them and tell developers exactly which standards apply to their feature and how to implement them. Writing good standards is now a superpower."

**Full Transcript Segment:**
"Yeah, exactly, because what I'm saying right now is that humans don't need to read security standards anymore. LLMs can read it and tell them exactly... so the problems that, you know, I used to face with developers is that you would have, like, a 50-page security standards document, and then you would give that to a developer, and the developer's writing a new feature, and let's say he's the most secure-conscious developer in the world, okay? He really... this person, this developer, they really care about this, right? So what they're doing is they're like, hey, I have to now find out, for my feature, which of these 275 security standards are applicable. That is not possible, right? But now, with LLMs, you can do that. You can actually say, hey, for the feature you're building, here are the... here's the metadata or the characteristics of this feature, and these are the standards which are applicable for them, and here's how you implement them... I kind of feel like writing good standards was almost done as a checkbox before, but now, writing good standards is a superpower, because if you have written good standards, if you've written libraries for them, if they're approved, if you have, like, secure pathways built out for your developers, you can finally actually communicate them very well with developers, and actually enforce them as well."

**Why It Works:**
Transformative insight about operationalizing compliance. Solves a problem everyone has (unread documentation). Shows positive AI application. Appeals to both security and compliance audiences. Actionable takeaway.

**Suggested Caption:**
That 50-page security standards doc nobody reads? LLMs can now translate it into actionable requirements for every feature. Game changer. ðŸ“šâ†’âš¡

**Hashtags:** #compliance #securitystandards #AI #automation #appsec

---

## Production Notes

- All clips are under 60 seconds (optimal for social media)
- Timestamps verified against VTT file
- Self-contained segments that work without additional context
- Mix of different content types (surprising, practical, philosophical, actionable)
- Prioritized by viral potential
- Each clip has platform-specific targeting
- Ready for video editing team

## File Reference

**Source:** users/ashish/defud/seezo/zoom/GMT20251017-160517_Recording.transcript.vtt
**Episode:** Default Podcast with Sandesh Mysore Anand (CISO CEO)
**Date:** October 17, 2025
