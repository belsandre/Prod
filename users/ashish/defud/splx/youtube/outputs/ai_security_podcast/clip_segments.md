# Viral Clip Segments - AI Security Podcast

**Episode:** The Def Podcast with Sandy Dun (SPLX)
**Source:** https://youtu.be/znrStq-RUT4?si=BfgA-4tF_Sw0fJOG
**Date Generated:** 2025-01-12

---

## Clip 1: The Cybersecurity Professor Witch Experiment

**Duration:** ~45 seconds (110 words)

**Clip Title:** "AI Thinks Cybersecurity Professors Look Like Witches"

**Content Segment:**
> "One of the experiments that I've run since the original release of Dolly is about every six months and with every new release I run an experiment. The first experiment I did was I asked it to create an image of a happy cyber security professor with a white horse and then I added one word cyber security into that dolly image generator and the first image was this really cute nice looking professor and as soon as I added the word cyber security she turned in she looked like a witch and I thought oh that's interesting that was my first indication of bias right that if they taught cyber security you were unattractive."

**Key Quote:**
"As soon as I added the word 'cyber security' she turned in‚Äîshe looked like a witch."

**Why It Works:**
Surprising, visual, relatable example of AI bias that anyone can understand. Shows real experimental methodology over 3 years. Humorous yet serious. Perfect for sparking debate about AI training data and bias. Memorable visual that sticks with people.

**Suggested Caption:**
When you add "cybersecurity" to an AI image prompt and the professor suddenly looks like a witch, you've found bias. Sandy Dun's 3-year DALL-E experiment reveals something fascinating about how AI sees security professionals.

**Target Platform:** LinkedIn + Twitter
**Best For:** Professional audience, sparks conversation about AI bias and ethics

**Video Editing Notes:**
- Start with visual of the original DALL-E output side-by-side if available
- Add text overlay of the key quote at the moment it's spoken
- End with thought-provoking question: "Who decides what's 'offensive' in AI?"

---

## Clip 2: The Gasoline Factory Analogy

**Duration:** ~35 seconds (85 words)

**Clip Title:** "Stop Throwing AI Into Your Broken Infrastructure"

**Content Segment:**
> "The one thing that I see frequently is people just kind of you know you have this really broken digital infrastructure that has all of this really bad stuff in it and then they throw AI on top of it. You know it's like no you know like that is like lighting a match in a gasoline factory. I mean it's you're only going to make things worse. So you really have to step take a step back and say okay what's our business objectives you know what are our business value workflows."

**Key Quote:**
"Throwing AI on top of broken digital infrastructure is like lighting a match in a gasoline factory."

**Why It Works:**
Visceral metaphor that any executive can visualize immediately. Speaks to a common mistake many organizations are making RIGHT NOW. Creates urgency. Warning + actionable direction (step back, assess objectives). Highly shareable analogy.

**Suggested Caption:**
If your digital infrastructure is already a mess, adding AI won't fix it. SPLX's Sandy Dun explains why this is the equivalent of lighting a match in a gasoline factory. üî•

**Target Platform:** LinkedIn
**Best For:** C-suite and enterprise decision-makers, IT leaders

**Video Editing Notes:**
- Visualize "gasoline factory" metaphor with graphics/animation
- Add fire emoji or warning graphics when quote is spoken
- Include text overlay: "Fix your foundation first"

---

## Clip 3: The 200-Prompt Test

**Duration:** ~42 seconds (105 words)

**Clip Title:** "Why We Tested One AI Prompt 200 Times"

**Content Segment:**
> "One of our customers came to us and said, 'Okay, we're deploying this internally. We want to make sure that our chatbot doesn't ever disclose another conversation to somebody else.' So, we tested it, but we had to test it 200 times. So that's another unique aspect of AI which before if you were doing QA testing you had okay here's what we tested here's an expected outcome and as soon as you got your expected outcome you pass the test anything that wasn't the expected outcome failed. So with non-deterministic systems you can run the same prompt five times 10 times in this case we ran it 200 times."

**Key Quote:**
"With non-deterministic systems, how many times do you run a prompt before you say you've met your expectations around safety and security?"

**Why It Works:**
Concrete, specific number (200) that shocks people and makes them stop scrolling. Reveals fundamental difference between traditional QA and AI testing. Raises important question about "good enough" thresholds. Technical credibility builder for SPLX.

**Suggested Caption:**
Traditional software testing: Run it once, get expected result, ship it. ‚úÖ AI testing: Run the same prompt 200 times and hope nothing breaks. ü§û This is why AI security is different.

**Target Platform:** LinkedIn + YouTube Shorts
**Best For:** Technical audience, product teams, QA engineers, security practitioners

**Video Editing Notes:**
- Animate counter going from 1 to 200 during the segment
- Split screen showing "Traditional QA" vs "AI QA" comparison
- End with question mark graphic: "How many times is enough?"

---

## Clip 4: Prompting in Navajo

**Duration:** ~38 seconds (95 words)

**Clip Title:** "Why Hackers Use Navajo to Attack AI Systems"

**Content Segment:**
> "For many of the successful attacks if you look at plying the prompter or anything from the BT6 teams like the prompts that they're doing they're pretty heavy. They're using obscure languages they're doing conversion they're putting it into images and so that's why the runtime is so important. Because if you see someone trying to prompt in Navajo, you know, that's not normal behavior. And so you can flag on that. It's finding tuning for keeping out the known bad. If it's a healthcare chatbot, it shouldn't be asking for poetry from the Tudor dynasty."

**Key Quote:**
"If you see someone trying to prompt in Navajo, that's not normal behavior."

**Why It Works:**
Unexpected, specific detail about real attack techniques that sounds almost unbelievable. Combines technical depth with accessibility. The Navajo + Tudor dynasty examples are memorable and shareable. Shows sophistication of attacks while explaining defense strategy (runtime detection).

**Suggested Caption:**
AI attackers are getting creative: obscure languages, image conversion, and poetry from the Tudor dynasty. üé≠ Here's how runtime detection catches what guardrails miss.

**Target Platform:** Twitter + LinkedIn
**Best For:** Technical security audience, InfoSec community, high shareability factor

**Video Editing Notes:**
- Show text examples in Navajo + Tudor poetry visually
- Highlight the absurdity with graphics/emojis
- Add text overlay: "Behavioral detection > static rules"

---

## Clip 5: Speed Wins Fights (OODA Loop Finale)

**Duration:** ~40 seconds (100 words)

**Clip Title:** "The Fighter Pilot Strategy for AI Security"

**Content Segment:**
> "Recognize that the biggest change with AI is speed. You no longer can move at a snail's pace to make decisions. Look at every process across your organization and say how do we do this more quickly. John Boyd created the OODA loop and the reason he did it was because he was a fighter pilot and he knew that when you're in a dog fight in the sky the person who could make a decision the fastest most often was the winner of the fight. And so being able to make decisions and then move forward, make a decision, observe, orient, decide and act."

**Key Quote:**
"The person who could make a decision the fastest was most often the winner of the fight."

**Why It Works:**
Powerful closing message with clear call to action. Fighter pilot metaphor is visceral and aspirational. OODA loop is recognizable framework that adds credibility. Speaks to leadership/strategy audience. Inspirational energy perfect for ending on.

**Suggested Caption:**
Fighter pilot John Boyd knew it: In a dogfight, speed of decision-making wins. üõ©Ô∏è In AI security, it's the same game. Sandy Dun's final advice for enterprises navigating the AI threat landscape.

**Target Platform:** LinkedIn
**Best For:** Leadership audience, strategic thinkers, executives

**Video Editing Notes:**
- Visualize OODA loop with circular graphics (Observe ‚Üí Orient ‚Üí Decide ‚Üí Act)
- Fighter pilot imagery or animation
- End with strong call-to-action text: "Decide faster or lose"

---

## Clip Production Checklist

### Pre-Production:
- [ ] Identify exact timestamps in source video for each clip
- [ ] Verify audio quality in selected segments
- [ ] Check for any visual elements to highlight
- [ ] Plan graphics/text overlays for each clip

### Production:
- [ ] Extract 5 video segments from source
- [ ] Add captions/subtitles for accessibility
- [ ] Insert text overlays with key quotes
- [ ] Add relevant graphics/animations
- [ ] Ensure each clip is under 60 seconds
- [ ] Export in multiple formats (square for IG, vertical for TikTok, 16:9 for YouTube)

### Post-Production:
- [ ] Clip 1: Witch Experiment - Posted on: _____ | Platform: _____ | Engagement: _____
- [ ] Clip 2: Gasoline Factory - Posted on: _____ | Platform: _____ | Engagement: _____
- [ ] Clip 3: 200 Tests - Posted on: _____ | Platform: _____ | Engagement: _____
- [ ] Clip 4: Navajo Prompting - Posted on: _____ | Platform: _____ | Engagement: _____
- [ ] Clip 5: OODA Loop - Posted on: _____ | Platform: _____ | Engagement: _____

### Quality Verification:
- [ ] Each clip is self-contained (makes sense without context)
- [ ] Duration under 60 seconds for all clips
- [ ] Captions are accurate and timed correctly
- [ ] Key quote is highlighted visually
- [ ] Audio is clear and balanced
- [ ] Video quality is consistent across all clips
- [ ] Platform-specific formatting is correct

---

## Content Series Strategy

### Week 1: Education Series
- Monday: Clip 3 (200 Tests) - Technical depth
- Wednesday: Clip 1 (Witch Experiment) - Accessible AI bias intro
- Friday: LinkedIn Post Variation 3 (Practical)

### Week 2: Threat Awareness Series
- Monday: Clip 4 (Navajo Prompting) - Attack sophistication
- Thursday: Clip 2 (Gasoline Factory) - Infrastructure warning
- Friday: LinkedIn Post Variation 2 (Contrarian)

### Week 3: Leadership Series
- Tuesday: Clip 5 (OODA Loop) - Strategic imperative
- Thursday: LinkedIn Post Variation 4 (Big Picture)

### Week 4: Engagement & Reflection
- Monday: LinkedIn Post Variation 1 (Personal Story)
- Wednesday: Compilation reel of all 5 clips (2-minute sizzle)

---

*Generated via podcast-marketer workflow*
*Note: Timestamp positions estimated from transcript content. Verify against actual video before editing.*
