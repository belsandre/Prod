# LinkedIn Posts: AI Security with Sandy Dun (SPLX)

## Variation 1: Personal Story Angle

**Hook + Post:**

I asked a 20-year security veteran which side is winning the AI security battle. Her answer surprised me.

Sandy Dun has reviewed more AI security products than anyone I know. She calls herself "Sandy the Dream Killer" because she tells founders when their products don't solve real CISO problems.

When I asked her about offense vs. defense in AI security, she didn't give me the doom and gloom I expected.

Yes, adversaries have the speed advantage. They don't need legal sign-off or compliance reviews. But that advantage is temporary.

What struck me most was her honesty about the industry's biggest blind spot: We've always done statistical security. We just weren't honest about it. Third party risk? Fourth party risk? We stopped looking because it was too hard.

AI is forcing that conversation into the open.

The real threat isn't attackers targeting AI models. It's attackers using AI to compress their attack cycle. Recon, vulnerability research, code conversion. All faster.

Sandy's advice for surviving this? One word: Speed.

In this episode of The Def Podcast, she breaks down what actually works in AI security, why most solutions miss the mark, and how to communicate AI risk to your board without the jargon.

Link in comments.

#aisecurity #cybersecurity #ciso

**Character count:** 1,247

---

## Variation 2: Contrarian/Surprising Angle

**Hook + Post:**

Attackers aren't trying to hack your AI models. They're using AI to hack you faster.

That's the uncomfortable truth Sandy Dun shared on The Def Podcast this week. Sandy has over 20 years in security, led OWASP AI security initiatives, and now works at SPLX, the company that recently demonstrated ChatGPT5's security vulnerabilities.

Here's what most AI security conversations get wrong:

Everyone's focused on prompt injection and model attacks. Those are real problems. But adversaries aren't going there yet. Why would they? They can use AI to find zero days that get exploited within 24 hours. That used to take months.

The sexy story is attacking the model. The real story is using the model to attack everything else.

Sandy also dropped this truth bomb: "It's mathematically impossible to do AI governance at the core level."

The attack surface is too vast. You can't test everything. So what do you do?

Move from binary security metrics to statistical thinking. Stop pretending you have full visibility. Start making investment decisions based on likelihood and impact.

And above all, move faster. Every process in your organization needs to answer: How do we do this more quickly?

Full conversation in comments.

#aisecurity #cybersecurity #threatintelligence

**Character count:** 1,198

---

## Variation 3: Practical/Actionable Angle

**Hook + Post:**

Your board wants to know about AI security risk. Here's how to answer in 30 seconds.

Sandy Dun calls it the "Smoky the Bear sign." Simple. Visual. What's the chance of fire?

I sat down with Sandy on The Def Podcast to talk about AI security, and she completely reframed how I think about board communication.

CISOs are risk managers. Your job isn't to give binary answers. It's to present likelihood and impact so the board can make investment decisions.

Here's her framework:

1. Present risk simply. Not technical jargon. Probability and impact.
2. Give two options: Accept the risk or invest to reduce it.
3. Frame security as investment, not insurance.

She also shared tactical advice for AI security posture:

Before deploying AI, fix your foundation. "Throwing AI on broken digital infrastructure is like lighting a match in a gasoline factory."

For testing non-deterministic systems, run prompts 200+ times. One pass isn't enough. You need statistical confidence.

And centralize your controls across ISO, SOC 2, HIPAA, PCI. Don't spend all your time on audits.

The biggest change with AI is speed. Sandy referenced the OODA loop. Fighter pilots who decide fastest win. Your security program needs that same mentality.

Listen to the full episode. Link in comments.

#cybersecurity #ciso #aisecurity

**Character count:** 1,210

---

## Variation 4: Big Picture/Trend Angle

**Hook + Post:**

The time to exploit a zero day dropped from months to 24 hours. AI accelerated the entire attack lifecycle.

This week's npm attacks and CrowdStrike compromise aren't anomalies. They're the new normal.

I talked with Sandy Dun about this on The Def Podcast. Sandy has spent 20 years in security, champions OWASP AI security initiatives, and works at SPLX on the front lines of AI red teaming.

Her take on where we're headed:

Supply chain attacks will dominate. Code is built from layers of packages. Remember Log4j? That wasn't one patch. It was hunting through third and fourth layer dependencies. Now imagine that with AI-generated code.

Traditional security metrics are obsolete. Binary pass/fail testing doesn't work for non-deterministic systems. You need to test the same prompt 200 times before you have statistical confidence.

Governance frameworks can't keep pace. California's SB1047 got attention, but there's also proposed legislation with $1,000 per incident fines for chatbots interacting with minors. The regulatory landscape is shifting fast.

The winners will be organizations that prioritize speed. Not just in response, but in decision-making. Sandy referenced John Boyd's OODA loop: Observe, Orient, Decide, Act. Repeat faster than your adversary.

AI security will get worse before it gets better. But the defenders who adapt to speed and statistical thinking will come out ahead.

Full conversation in comments.

#aisecurity #cybersecurity #supplychain

**Character count:** 1,348

---

*Posts generated using podcast-marketer workflow*
